# Sorting

## Sorting Algorithms
There are various sorting algorithms in computer science, each with its own advantages, disadvantages, and use cases.

    Bubble Sort:
        Simple and easy to understand.
        Time complexity: O(n^2) in the worst and average cases.
        Inefficient for large datasets.

    Selection Sort:
        Simple and easy to implement.
        Time complexity: O(n^2) in the worst and average cases.
        Inefficient for large datasets.

    Insertion Sort:
        Efficient for small datasets and partially sorted arrays.
        Time complexity: O(n^2) in the worst and average cases.

    Quick Sort:
        Efficient and widely used.
        Time complexity: O(n log n) in the average case, O(n^2) in the worst case.
        Often faster than other sorting algorithms for large datasets.

    Merge Sort:
        Stable and efficient.
        Time complexity: O(n log n) in all cases.
        Guarantees worst-case performance.

    Heap Sort:
        Efficient and in-place sorting.
        Time complexity: O(n log n) in all cases.
        Not as widely used as Quick Sort or Merge Sort.

    Shell Sort:
        Variation of Insertion Sort with better performance.
        Time complexity: Depends on the gap sequence used (can be better than O(n^2)).

    Counting Sort:
        Ideal for sorting integers with a limited range.
        Time complexity: O(n + k), where k is the range of integers.

    Radix Sort:
        Sorts numbers digit by digit.
        Time complexity: O(n * k), where k is the number of digits.

    Bucket Sort:
        Distributes elements into buckets and sorts each bucket.
        Time complexity: O(n^2) in the worst case, O(n + k) on average.